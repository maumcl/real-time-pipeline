# Real-Time Data Pipeline with Kafka, Spark, and BigQuery  

## ðŸ“Œ Description  
This project implements a **real-time data pipeline**, using **Apache Kafka** for data ingestion, **Apache Spark Streaming** for processing, and **Google BigQuery** for later analysis.  

The dataset consists of user activity data, including steps, calories burned, distance traveled, heart rate, and sleep hours.  

---

## ðŸ“‚ Technologies Used  

- **ðŸ Python**  
- **ðŸ›  Apache Kafka** - Message broker for real-time data ingestion  
- **âš¡ Apache Spark Streaming** - Stream processing framework  
- **â˜ Google BigQuery** - Storage and analytics platform  
- **ðŸ³ Docker** - For easy service setup  

---

## ðŸ”§ Project Architecture  

```plaintext
User -> Kafka (Producer) -> Kafka (Broker) -> Spark Streaming (Consumer) -> BigQuery