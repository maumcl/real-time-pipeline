# **Real-Time Data Pipeline with Kafka, Spark, and BigQuery**

## ðŸ“Œ **Description**  
This project implements a real-time data pipeline using **Apache Kafka** for data ingestion, **Apache Spark Streaming** for processing, and **Google BigQuery** for storage and analysis.  

The dataset consists of **simulated user activity data**, including metrics related to steps, calories burned, distance traveled, heart rate, and sleep patterns. These records are continuously produced and consumed in real-time to demonstrate a streaming ETL workflow.  

## ðŸ“‚ **Technologies Used**  
- ðŸ **Python** â€“ Core programming language  
- ðŸ›  **Apache Kafka** â€“ Message broker for real-time data ingestion  
- âš¡ **Apache Spark Streaming** â€“ Stream processing framework  
- â˜ **Google BigQuery** â€“ Storage and analytics platform  
- ðŸ³ **Docker** â€“ Containerization for easy service setup  

## ðŸ”§ **Project Architecture**  
```plaintext
User -> Kafka (Producer) -> Kafka (Broker) -> Spark Streaming (Consumer) -> BigQuery
```

1. **Producer**: Generates simulated user activity data and sends it to Kafka.  
2. **Kafka (Broker)**: Acts as a real-time event bus.  
3. **Spark Streaming (Consumer)**: Reads the streaming data from Kafka, processes it, and prepares it for storage.  
4. **BigQuery**: Stores the processed data for further analysis.  

## ðŸ“Š **Streaming Data Schema**  
Each record in the stream represents **a user activity event** with the following attributes:  

| Column              | Type      | Description                                      |
|---------------------|----------|--------------------------------------------------|
| `user_id`          | Integer   | Unique identifier for the user                   |
| `date`             | String    | Activity date (YYYY-MM-DD)                      |
| `steps`            | Integer   | Number of steps taken                           |
| `calories_burned`  | Float     | Calories burned during the activity             |
| `distance_km`      | Float     | Distance covered (in km)                        |
| `active_minutes`   | Integer   | Active minutes during the day                   |
| `sleep_hours`      | Float     | Total sleep duration in hours                   |
| `heart_rate_avg`   | Integer   | Average heart rate (bpm)                        |
| `workout_type`     | String    | Type of workout (e.g., running, cycling, yoga)  |
| `weather_conditions` | String  | Weather during the activity (e.g., sunny, rainy) |
| `location`         | String    | Userâ€™s location (e.g., New York, Tokyo, Sydney) |
| `mood`            | String     | User's mood (happy, neutral, sad)               |

## ðŸš€ **Next Steps**  
- âœ… **Ensure Kafka is properly handling message ingestion**  
- âœ… **Process data using Spark Streaming**  
- ðŸ”œ **Write the processed data to Google BigQuery**  
- ðŸ”œ **Perform analytical queries on BigQuery for insights**  

